{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: meta-ai-api in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (1.2.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from meta-ai-api) (2.32.3)\n",
      "Requirement already satisfied: requests-html in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from meta-ai-api) (0.10.0)\n",
      "Requirement already satisfied: lxml-html-clean in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from meta-ai-api) (0.3.1)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: lxml in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from lxml-html-clean->meta-ai-api) (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests->meta-ai-api) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests->meta-ai-api) (1.26.20)\n",
      "Requirement already satisfied: pyquery in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests-html->meta-ai-api) (2.0.1)\n",
      "Requirement already satisfied: fake-useragent in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests-html->meta-ai-api) (1.5.1)\n",
      "Requirement already satisfied: parse in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests-html->meta-ai-api) (1.20.2)\n",
      "Requirement already satisfied: bs4 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests-html->meta-ai-api) (0.0.2)\n",
      "Requirement already satisfied: w3lib in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests-html->meta-ai-api) (2.2.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from requests-html->meta-ai-api) (2.0.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from pyppeteer>=0.0.14->requests-html->meta-ai-api) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from pyppeteer>=0.0.14->requests-html->meta-ai-api) (8.5.0)\n",
      "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from pyppeteer>=0.0.14->requests-html->meta-ai-api) (11.1.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from pyppeteer>=0.0.14->requests-html->meta-ai-api) (10.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from bs4->requests-html->meta-ai-api) (4.12.3)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from pyquery->requests-html->meta-ai-api) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->meta-ai-api) (3.20.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (from beautifulsoup4->bs4->requests-html->meta-ai-api) (2.6)\n",
      "Downloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 distro-1.9.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.7.0 openai-1.54.3 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install meta-ai-api openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"\"\n",
    "openai_api_key_2 = \"\"\n",
    "mistral_ai_key = \"\"\n",
    "JAMBA_API_KEY = ''\n",
    "JAMBA_API_URL = 'https://api.ai21.com/studio/v1/chat/completions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_client = OpenAI(api_key=openai_api_key_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages/requests/models.py:754: RuntimeWarning: coroutine 'ask_sydney_async' was never awaited\n",
      "  @property\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from meta_ai_api import MetaAI # no api key needed :O\n",
    "\n",
    "meta_ai = MetaAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /home/chris/Documents/UT/SWTest/project/QualitySoftware/venv/lib/python3.12/site-packages (1.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_jamba(message):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {JAMBA_API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"jamba-1.5-large\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(JAMBA_API_URL, headers=headers, json=data)\n",
    "    response.raise_for_status()  # Raises an error if the request failed\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_prompt_openai(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Submits a prompt to ChatGPT and returns the response message.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to submit.\n",
    "        model (str): The model to use (default is \"gpt-4o\").\n",
    "\n",
    "    Returns:\n",
    "        str: The response message from ChatGPT.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt}]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing the \"best\" French cheese can be subjective as it greatly depends on personal taste. France is renowned for its wide variety of cheeses, with over 400 different types. Here are a few highly regarded French cheeses across various categories:\n",
      "\n",
      "1. **Soft Cheeses:**\n",
      "   - **Brie de Meaux**: Known for its creamy texture and rich, slightly nutty flavor.\n",
      "   - **Camembert de Normandie**: Soft and creamy with a distinctive earthy taste.\n",
      "\n",
      "2. **Semi-Soft Cheeses:**\n",
      "   - **Reblochon**: A nutty and fruity cheese from the Alps, often used in tartiflette.\n",
      "   - **Morbier**: Recognizable by its layer of ash in the middle, it has a creamy texture and a fruity, slightly smoky flavor.\n",
      "\n",
      "3. **Hard Cheeses:**\n",
      "   - **Comté**: A firm, nutty, and sweet cheese made from unpasteurized cow's milk.\n",
      "   - **Beaufort**: Similar to Comté but with a more pronounced, complex flavor.\n",
      "\n",
      "4. **Blue Cheeses:**\n",
      "   - **Roquefort**: A tangy and salty sheep milk cheese with distinctive veins of blue mold.\n",
      "   - **Bleu d'Auvergne**: A creamy and milder blue cheese with a slightly spicy taste.\n",
      "\n",
      "5. **Goat Cheeses:**\n",
      "   - **Chèvre**: Found in many varieties, such as Crottin de Chavignol, which has a tangy, earthy flavor.\n",
      "   - **Sainte-Maure de Touraine**: A log-shaped goat cheese with a creamy texture and a mild, nutty flavor.\n",
      "\n",
      "Each of these cheeses has its unique characteristics, so the \"best\" one depends on your personal preferences. It's always fun to try several types to discover your favorite!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = Mistral(api_key=mistral_ai_key)\n",
    "\n",
    "chat_response = client.chat.complete(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the best French cheese?\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from sydney import SydneyClient # copilot at home\n",
    "\n",
    "async def get_response(prompt: str) -> str:\n",
    "    async with SydneyClient() as sydney:\n",
    "        response = \"\"\n",
    "        async for chunk in sydney.ask_stream(prompt):\n",
    "            response += chunk\n",
    "        return response\n",
    "\n",
    "# Function to be used in Jupyter Notebook\n",
    "async def ask_sydney(prompt: str):\n",
    "    \"\"\"goofy ah\"\"\"\n",
    "    try:\n",
    "        response = await get_response(prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A picnic 🧺 is a great way to enjoy nature and have some fun with your friends or family. You should bring along some sandwiches, fruits 🍎, drinks 🥤, snacks 🍪, games 🎮, and a blanket 🛏. What kind of picnic are you planning?\n"
     ]
    }
   ],
   "source": [
    "message = await ask_sydney(\"What should I bring for my upcoming picnic?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_from_llm_response(llm_response: str) -> str:\n",
    "    \"\"\"try to parse the java program from the input llm response\"\"\"\n",
    "    # look for key words denoting the start of a java program\n",
    "    key_words = [\"import\", \"package\", \"public class\"]\n",
    "    for key_word in key_words:\n",
    "        start_index = llm_response.find(key_word)\n",
    "        if (start_index != -1):\n",
    "            break\n",
    "    if (start_index == -1):\n",
    "        print(\"ERROR: unable to find start of java program\")\n",
    "        return \"\"\n",
    "    # look for the closing curly brace for the end of the java program\n",
    "    end_index = llm_response.rfind(\"}\") + 1\n",
    "    if (end_index == -1):\n",
    "        print(\"ERROR: unable to find end of java program\")\n",
    "        return \"\"\n",
    "    # return the found program\n",
    "    generated_code = llm_response[start_index:end_index]\n",
    "    return generated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name_from_generated_code(generated_code: str) -> str:\n",
    "    match = re.search(r'public class (\\w+)', generated_code)\n",
    "    if (match):\n",
    "        class_name = match.group(1)\n",
    "        return class_name\n",
    "    else:\n",
    "        print(\"ERROR: class name not found in generated code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_package_and_import_to_generated_code(package_name: str, class_under_test: str, generated_code: str) -> str:\n",
    "    import_statement = f'import {class_under_test};'\n",
    "    return f\"package {package_name};\\n\" + f\"{import_statement}\\n\\n\" + generated_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(prompt: str, llm: str, package_name: str, class_name: str, write_output: bool = False) -> None:\n",
    "    print(\"Generating code...\")\n",
    "\n",
    "    file_path = f\"../prompts/{package_name}/{prompt}.txt\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        prompt_text = file.read()\n",
    "\n",
    "    if (llm==\"metaAI\"):\n",
    "        response = meta_ai.prompt(message=prompt_text)\n",
    "        message = response[\"message\"]\n",
    "    elif (llm==\"ai21Jamba\"):\n",
    "        response = send_message_to_jamba(prompt_text)\n",
    "        message = response['choices'][0]['message']['content']\n",
    "    elif (llm==\"chatGPT4o\"):\n",
    "        message = submit_prompt_openai(prompt_text, model='gpt-4o')\n",
    "    elif (llm==\"chatGPTo1Preview\"):\n",
    "        print(\"Error, o1-preview not available via API :/\")\n",
    "    elif (llm==\"copilot\"):\n",
    "        message = asyncio.run(ask_sydney(prompt_text))\n",
    "    else: \n",
    "        print(\"Error, llm not supported, please pick a valid option\")\n",
    "        return\n",
    "\n",
    "    print(message)\n",
    "\n",
    "    generated_code = extract_code_from_llm_response(message)\n",
    "    package = f\"{package_name}.{llm}.{prompt}\"\n",
    "    class_under_test = f\"{package_name}.{class_name}\"\n",
    "    generated_code = add_package_and_import_to_generated_code(package, class_under_test, generated_code)\n",
    "\n",
    "\n",
    "    if (write_output):\n",
    "        output_filename = f\"../src/test/java/{package_name}/{llm}/{prompt}/{class_name}Test.java\"\n",
    "        with open(output_filename, 'w') as file:\n",
    "            file.write(generated_code)\n",
    "        print(\"Wrote generated code to \", output_filename)\n",
    "    else:\n",
    "        print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating code...\n",
      "Sure, I can write a test suite for you. Here is the test case: @Test public void test_grouping() { assertEquals(3, strs.length); // make sure there are three strings in the array String[] expected = {\"a\", \"b\", \"c\"}; // create a new array of arrays with three elements ArrayList<ArrayList<String>> result = new ArrayList<>(); // loop through each string and create a new array of arrays for (int i = 0; i < strs.length; i++) { // get the first element of the current string String current = strs[i]; // get the second element of the current string String second = strs[i + 1]; // add them to the current array of arrays ArrayList<String> temp = new ArrayList<>(); // add them to the temp array temp.add(current); temp.add(\n",
      "ERROR: unable to find start of java program\n",
      "package anagrams.copilot.prompt1;\n",
      "import anagrams.Anagrams;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_code(\"prompt1\", \"copilot\", \"anagrams\", \"Anagrams\", write_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
